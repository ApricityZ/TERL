apf:
  force_range: 15.0
env:
  boundary_penalty: -5.0
  capture_distance: 8.0
  clear_r: 15.0
  collision_penalty: -80.0
  decay_factor: -0.05
  distance_reward: 5.0
  emergency_penalty: -5.0
  evenly_distributed_reward: 5.0
  goal_reward: 120.0
  height: 120.0
  obs_r_range:
  - 1.0
  - 1.1
  related_distance: 18.0
  timestep_penalty: -1.0
  unevenly_distributed_reward: -10.0
  width: 120.0
evader:
  a:
  - -0.4
  - 0.0
  - 0.4
  max_speed: 3.5
  perception_range: 20.0
  w:
  - -0.5235987755982988
  - -0.2617993877991494
  - 0.0
  - 0.2617993877991494
  - 0.5235987755982988
eval_freq: 200000
eval_schedule:
  min_pursuer_evader_init_dis:
  - 20.0
  - 20.0
  - 20.0
  - 20.0
  - 20.0
  num_cores:
  - 4
  - 6
  - 8
  - 8
  - 8
  num_episodes:
  - 20
  - 20
  - 20
  - 20
  - 20
  num_evaders:
  - 1
  - 2
  - 3
  - 4
  - 5
  num_obstacles:
  - 0
  - 2
  - 4
  - 6
  - 8
  num_pursuers:
  - 3
  - 7
  - 11
  - 15
  - 18
exp_schedule:
  min_pursuer_evader_init_dis:
  - 10.0
  - 13.0
  - 15.0
  - 20.0
  - 20.0
  num_cores:
  - 4
  - 6
  - 8
  - 8
  - 8
  num_episodes:
  - 20
  - 20
  - 20
  - 20
  - 20
  num_evaders:
  - 1
  - 2
  - 3
  - 4
  - 5
  num_obstacles:
  - 0
  - 2
  - 4
  - 6
  - 8
  num_pursuers:
  - 3
  - 7
  - 11
  - 15
  - 18
off_policy: true
perception:
  max_evader_num: 8
pursuer:
  a:
  - -0.4
  - 0.0
  - 0.4
  distance_capture: env.capture_distance
  max_speed: 3.0
  perception_range: 20.0
  w:
  - -0.5235987755982988
  - 0.0
  - 0.5235987755982988
save_dir: /home/zhangheng/dqn-model
seed: 9
total_timesteps: 7000000
training:
  episode_max_length: 3000
  update_every: 4
training_schedule:
  min_pursuer_evader_init_dis:
  - 10.0
  - 13.0
  - 15.0
  - 20.0
  - 20.0
  num_cores:
  - 4
  - 6
  - 8
  - 8
  - 8
  num_evaders:
  - 1
  - 1
  - 2
  - 3
  - 4
  num_obstacles:
  - 0
  - 1
  - 2
  - 4
  - 6
  num_pursuers:
  - 3
  - 4
  - 7
  - 11
  - 15
  time_steps:
  - 0
  - 2000000
  - 4000000
  - 5000000
  - 6000000
training_time: 2025-02-13-15-47-44
use_iqn: false
use_mix: false
